{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JGExvxRID2DV",
        "outputId": "cdf8aa5f-0925-4772-f27b-42e44cd1c54f"
      },
      "source": [
        "!pip install -r '/content/drive/MyDrive/CMU/SP21/18786-IDL/11785-final-project/requirements.txt'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting imageio==2.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/CMU/SP21/18786-IDL/11785-final-project/requirements.txt (line 2)) (1.19.5)\n",
            "Collecting opencv-python==4.5.1.48\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/13/192104516c4a3d92dc6b5e106ffcfbf0fe35f3c4faa49650205ff652af72/opencv_python-4.5.1.48-cp37-cp37m-manylinux2014_x86_64.whl (50.4MB)\n",
            "\u001b[K     |████████████████████████████████| 50.4MB 109kB/s \n",
            "\u001b[?25hCollecting Pillow==4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/73/66854f63b1941aad9af18a1de59f9cf95ad1a87c801540222e332f6688d7/Pillow-4.1.1.tar.gz (11.3MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3MB 33.5MB/s \n",
            "\u001b[?25hCollecting scipy==1.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/91/ee427c42957f8c4cbe477bf4f8b7f608e003a17941e509d1777e58648cb3/scipy-1.6.2-cp37-cp37m-manylinux1_x86_64.whl (27.4MB)\n",
            "\u001b[K     |████████████████████████████████| 27.4MB 111kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/CMU/SP21/18786-IDL/11785-final-project/requirements.txt (line 6)) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision==0.9.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/CMU/SP21/18786-IDL/11785-final-project/requirements.txt (line 7)) (0.9.1+cu101)\n",
            "Collecting tqdm==4.59.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/3e/2730d0effc282960dbff3cf91599ad0d8f3faedc8e75720fdf224b31ab24/tqdm-4.59.0-py2.py3-none-any.whl (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions==3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/CMU/SP21/18786-IDL/11785-final-project/requirements.txt (line 9)) (3.7.4.3)\n",
            "Collecting olefile\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/81/e1ac43c6b45b4c5f8d9352396a14144bba52c8fec72a80f425f6a4d653ad/olefile-0.46.zip (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 49.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: Pillow, olefile\n",
            "  Building wheel for Pillow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Pillow: filename=Pillow-4.1.1-cp37-cp37m-linux_x86_64.whl size=1009522 sha256=f2a69e4b7c567bb5386fdee686401da6bfd750e6e805f357e2ebc0f1770f1896\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/f3/3e/f24b51fe136968f797933559011acd48b16708fc306c924770\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35416 sha256=ff0d788f45c8a7ef870041822e52a0b32d1657040c167684f037110b9d5b6f65\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/f4/11/bc4166107c27f07fd7bba707ffcb439619197638a1ac986df3\n",
            "Successfully built Pillow olefile\n",
            "\u001b[31mERROR: scikit-image 0.16.2 has requirement pillow>=4.3.0, but you'll have pillow 4.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: bokeh 2.3.1 has requirement pillow>=7.1.0, but you'll have pillow 4.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: olefile, Pillow, imageio, opencv-python, scipy, tqdm\n",
            "  Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed Pillow-4.1.1 imageio-2.9.0 olefile-0.46 opencv-python-4.5.1.48 scipy-1.6.2 tqdm-4.59.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-91BmVIGgOos",
        "outputId": "e19852a8-e963-4b74-a7f4-8d33b367a527"
      },
      "source": [
        "!git clone --single-branch --branch main https://[GITHUB_TOKEN]@github.com/hans-lizihan/11785-project.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '11785-project'...\n",
            "remote: Enumerating objects: 45727, done.\u001b[K\n",
            "remote: Counting objects: 100% (14904/14904), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14896/14896), done.\u001b[K\n",
            "remote: Total 45727 (delta 25), reused 14885 (delta 7), pack-reused 30823\u001b[K\n",
            "Receiving objects: 100% (45727/45727), 1.92 GiB | 40.70 MiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n",
            "Checking out files: 100% (64479/64479), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X3isBewUVaE"
      },
      "source": [
        "import imageio\n",
        "import itertools\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import cv2, os\n",
        "from tqdm import tqdm\n",
        "import os, time, pickle, argparse\n",
        "import torch.optim as optim\n",
        "from google.colab.patches import cv2_imshow\n",
        "from pathlib import Path\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54q-t5VoyNFP"
      },
      "source": [
        "def pre_process(img_rgb):\n",
        "  num_down = 2       # number of downsampling steps\n",
        "  num_bilateral = 7  # number of bilateral filtering steps\n",
        "\n",
        "  # downsample image using Gaussian pyramid\n",
        "  img_color = img_rgb\n",
        "  for _ in range(num_down):\n",
        "    img_color = cv2.pyrDown(img_color)\n",
        "\n",
        "  # repeatedly apply small bilateral filter instead of\n",
        "  # applying one large filter\n",
        "  for _ in range(num_bilateral):\n",
        "    img_color = cv2.bilateralFilter(img_color, d=9,\n",
        "                      sigmaColor=9,\n",
        "                      sigmaSpace=7)\n",
        "\n",
        "  # upsample image to original size\n",
        "  for _ in range(num_down):\n",
        "    img_color = cv2.pyrUp(img_color)\n",
        "\n",
        "  # convert to grayscale and apply median blur\n",
        "  img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "  img_blur = cv2.medianBlur(img_gray, 7)\n",
        "\n",
        "  # detect and enhance edges\n",
        "  img_edge = cv2.adaptiveThreshold(img_blur, 255,\n",
        "                    cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "                    cv2.THRESH_BINARY,\n",
        "                    blockSize=5,\n",
        "                    C=2)\n",
        "\n",
        "  # convert back to color, bit-AND with color image\n",
        "  img_edge = cv2.cvtColor(img_edge, cv2.COLOR_GRAY2RGB)\n",
        "  img_cartoon = cv2.bitwise_and(img_color, img_edge)\n",
        "\n",
        "  # display\n",
        "  #cv2_imshow(img_cartoon)\n",
        "  return img_cartoon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oni6ADTqzw3H"
      },
      "source": [
        "def edge_mask(img, line_size=7, blur_value=7):\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  gray_blur = cv2.medianBlur(gray, blur_value)\n",
        "  edges = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, line_size, blur_value)\n",
        "  return edges\n",
        "\n",
        "def color_quantization(img, k=9):\n",
        "# Transform the image\n",
        "  data = np.float32(img).reshape((-1, 3))\n",
        "\n",
        "# Determine criteria\n",
        "  criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 0.001)\n",
        "\n",
        "# Implementing K-Means\n",
        "  ret, label, center = cv2.kmeans(data, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "  center = np.uint8(center)\n",
        "  result = center[label.flatten()]\n",
        "  result = result.reshape(img.shape)\n",
        "  return result\n",
        "\n",
        "def pre_process2(img_rgb):\n",
        "  line_size = 7\n",
        "  blur_value = 7\n",
        "  edges = edge_mask(img_rgb, line_size, blur_value)\n",
        "\n",
        "  total_color = 9\n",
        "  img = color_quantization(img_rgb, total_color)\n",
        "\n",
        "  blurred = cv2.bilateralFilter(img, d=7, sigmaColor=200,sigmaSpace=200)\n",
        "  cartoon = cv2.bitwise_and(blurred, blurred, mask=edges)\n",
        "  #cv2_imshow(cartoon)\n",
        "  return cartoon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBEk4q8T1ZWe",
        "outputId": "048eb8cc-c06b-4483-a552-0c3200fa6f97"
      },
      "source": [
        "# img_rgb = cv2.imread(\"/content/11785-project/data/src_flame/test/18212223_2c45a53a4a.jpg\")\n",
        "# pre_process(img_rgb)\n",
        "# pre_process2(img_rgb)\n",
        "\n",
        "def preprocessFolder(src, tgt):\n",
        "    Path(tgt).mkdir(parents=True, exist_ok=True)\n",
        "    for filename in tqdm(os.listdir(src), total=len(os.listdir(src))):\n",
        "        img = cv2.imread(os.path.join(src,filename))\n",
        "        if img is not None:\n",
        "            cartoon = pre_process2(img)\n",
        "            cv2.imwrite(os.path.join(tgt, filename), cartoon)\n",
        "            \n",
        "            \n",
        "preprocessFolder(\"/content/11785-project/data/src_flame/train/\", \"/content/11785-project/data/src_cartoonflame/train/\")\n",
        "preprocessFolder(\"/content/11785-project/data/src_flame/test/\", \"/content/11785-project/data/src_cartoonflame/test/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 991/991 [06:53<00:00,  2.40it/s]\n",
            "100%|██████████| 9/9 [00:03<00:00,  2.42it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ff6iqWqyMa9"
      },
      "source": [
        "def data_load(path, subfolder, transform, batch_size, shuffle=False, drop_last=True):\n",
        "    dset = datasets.ImageFolder(path, transform)\n",
        "    ind = dset.class_to_idx[subfolder]\n",
        "\n",
        "    n = 0\n",
        "    for i in range(dset.__len__()):\n",
        "        if ind != dset.imgs[n][1]:\n",
        "            del dset.imgs[n]\n",
        "            n -= 1\n",
        "\n",
        "        n += 1\n",
        "\n",
        "    return torch.utils.data.DataLoader(dset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
        "\n",
        "def print_network(net):\n",
        "    num_params = 0\n",
        "    for param in net.parameters():\n",
        "        num_params += param.numel()\n",
        "    print(net)\n",
        "    print('Total number of parameters: %d' % num_params)\n",
        "\n",
        "def initialize_weights(net):\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            m.weight.data.normal_(0, 0.02)\n",
        "            m.bias.data.zero_()\n",
        "        elif isinstance(m, nn.ConvTranspose2d):\n",
        "            m.weight.data.normal_(0, 0.02)\n",
        "            m.bias.data.zero_()\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            m.weight.data.normal_(0, 0.02)\n",
        "            m.bias.data.zero_()\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            m.weight.data.fill_(1)\n",
        "            m.bias.data.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q2PqsnwUOMb"
      },
      "source": [
        "class resnet_block(nn.Module):\n",
        "    def __init__(self, channel, kernel, stride, padding):\n",
        "        super(resnet_block, self).__init__()\n",
        "        self.channel = channel\n",
        "        self.kernel = kernel\n",
        "        self.strdie = stride\n",
        "        self.padding = padding\n",
        "        self.conv1 = nn.Conv2d(channel, channel, kernel, stride, padding)\n",
        "        self.conv1_norm = nn.InstanceNorm2d(channel)\n",
        "        self.conv2 = nn.Conv2d(channel, channel, kernel, stride, padding)\n",
        "        self.conv2_norm = nn.InstanceNorm2d(channel)\n",
        "\n",
        "        initialize_weights(self)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = F.relu(self.conv1_norm(self.conv1(input)), True)\n",
        "        x = self.conv2_norm(self.conv2(x))\n",
        "\n",
        "        return input + x #Elementwise Sum\n",
        " \n",
        "\n",
        "class generator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self, in_nc, out_nc, nf=32, nb=6):\n",
        "        super(generator, self).__init__()\n",
        "        self.input_nc = in_nc\n",
        "        self.output_nc = out_nc\n",
        "        self.nf = nf\n",
        "        self.nb = nb\n",
        "        self.down_convs = nn.Sequential(\n",
        "            nn.Conv2d(in_nc, nf, 7, 1, 3), #k7n64s1\n",
        "            nn.InstanceNorm2d(nf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(nf, nf * 2, 3, 2, 1), #k3n128s2\n",
        "            nn.Conv2d(nf * 2, nf * 2, 3, 1, 1), #k3n128s1\n",
        "            nn.InstanceNorm2d(nf * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(nf * 2, nf * 4, 3, 2, 1), #k3n256s1\n",
        "            nn.Conv2d(nf * 4, nf * 4, 3, 1, 1), #k3n256s1\n",
        "            nn.InstanceNorm2d(nf * 4),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        self.resnet_blocks = []\n",
        "        for i in range(nb):\n",
        "            self.resnet_blocks.append(resnet_block(nf * 4, 3, 1, 1))\n",
        "\n",
        "        self.resnet_blocks = nn.Sequential(*self.resnet_blocks)\n",
        "\n",
        "        self.up_convs = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nf * 4, nf * 2, 3, 2, 1, 1), #k3n128s1/2\n",
        "            nn.Conv2d(nf * 2, nf * 2, 3, 1, 1), #k3n128s1\n",
        "            nn.InstanceNorm2d(nf * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(nf * 2, nf, 3, 2, 1, 1), #k3n64s1/2\n",
        "            nn.Conv2d(nf, nf, 3, 1, 1), #k3n64s1\n",
        "            nn.InstanceNorm2d(nf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(nf, out_nc, 7, 1, 3), #k7n3s1\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "        initialize_weights(self)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, input):\n",
        "        x = self.down_convs(input)\n",
        "        x = self.resnet_blocks(x)\n",
        "        output = self.up_convs(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class discriminator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self, in_nc, out_nc, nf=32):\n",
        "        super(discriminator, self).__init__()\n",
        "        self.input_nc = in_nc\n",
        "        self.output_nc = out_nc\n",
        "        self.nf = nf\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv2d(in_nc, nf, 3, 1, 1),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(nf, nf * 2, 3, 2, 1),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(nf * 2, nf * 4, 3, 1, 1),\n",
        "            nn.InstanceNorm2d(nf * 4),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(nf * 4, nf * 4, 3, 2, 1),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(nf * 4, nf * 8, 3, 1, 1),\n",
        "            nn.InstanceNorm2d(nf * 8),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(nf * 8, nf * 8, 3, 1, 1),\n",
        "            nn.InstanceNorm2d(nf * 8),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(nf * 8, out_nc, 3, 1, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "        initialize_weights(self)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, input):\n",
        "        # input = torch.cat((input1, input2), 1)\n",
        "        output = self.convs(input)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class VGG19(nn.Module):\n",
        "    def __init__(self, init_weights=None, feature_mode=False, batch_norm=False, num_classes=1000):\n",
        "        super(VGG19, self).__init__()\n",
        "        self.cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
        "        self.init_weights = init_weights\n",
        "        self.feature_mode = feature_mode\n",
        "        self.batch_norm = batch_norm\n",
        "        self.num_clases = num_classes\n",
        "        self.features = self.make_layers(self.cfg, batch_norm)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "        if not init_weights == None:\n",
        "            self.load_state_dict(torch.load(init_weights))\n",
        "\n",
        "    def make_layers(self, cfg, batch_norm=False):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for v in cfg:\n",
        "            if v == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "                if batch_norm:\n",
        "                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "                else:\n",
        "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "                in_channels = v\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.feature_mode:\n",
        "            module_list = list(self.features.modules())\n",
        "            for l in module_list[1:27]:                 # conv4_4\n",
        "                x = l(x)\n",
        "        if not self.feature_mode:\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = self.classifier(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEIYX2rsVd-T"
      },
      "source": [
        "\n",
        "\n",
        "def edge_promoting(root, save):\n",
        "    file_list = os.listdir(root)\n",
        "    if not os.path.isdir(save):\n",
        "        os.makedirs(save)\n",
        "    kernel_size = 5\n",
        "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
        "    gauss = cv2.getGaussianKernel(kernel_size, 0)\n",
        "    gauss = gauss * gauss.transpose(1, 0)\n",
        "    n = 1\n",
        "    for f in tqdm(file_list):\n",
        "        rgb_img = cv2.imread(os.path.join(root, f))\n",
        "        gray_img = cv2.imread(os.path.join(root, f), 0)\n",
        "        rgb_img = cv2.resize(rgb_img, (256, 256))\n",
        "        pad_img = np.pad(rgb_img, ((2,2), (2,2), (0,0)), mode='reflect')\n",
        "        gray_img = cv2.resize(gray_img, (256, 256))\n",
        "        edges = cv2.Canny(gray_img, 100, 200)\n",
        "        dilation = cv2.dilate(edges, kernel)\n",
        "\n",
        "        gauss_img = np.copy(rgb_img)\n",
        "        idx = np.where(dilation != 0)\n",
        "        for i in range(np.sum(dilation != 0)):\n",
        "            gauss_img[idx[0][i], idx[1][i], 0] = np.sum(np.multiply(pad_img[idx[0][i]:idx[0][i] + kernel_size, idx[1][i]:idx[1][i] + kernel_size, 0], gauss))\n",
        "            gauss_img[idx[0][i], idx[1][i], 1] = np.sum(np.multiply(pad_img[idx[0][i]:idx[0][i] + kernel_size, idx[1][i]:idx[1][i] + kernel_size, 1], gauss))\n",
        "            gauss_img[idx[0][i], idx[1][i], 2] = np.sum(np.multiply(pad_img[idx[0][i]:idx[0][i] + kernel_size, idx[1][i]:idx[1][i] + kernel_size, 2], gauss))\n",
        "\n",
        "        result = np.concatenate((rgb_img, gauss_img), 1)\n",
        "\n",
        "        cv2.imwrite(os.path.join(save, str(n) + '.png'), result)\n",
        "        n += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wGF6eEyDtAD"
      },
      "source": [
        "def main(argv):\n",
        "\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument('--name', required=False, default='project_name',  help='')\n",
        "  parser.add_argument('--src_data', required=False, default='src_data_path',  help='sec data path')\n",
        "  parser.add_argument('--tgt_data', required=False, default='tgt_data_path',  help='tgt data path')\n",
        "  parser.add_argument('--vgg_model', required=False, default='pre_trained_VGG19_model_path/vgg19.pth', help='pre-trained VGG19 model path')\n",
        "  parser.add_argument('--in_ngc', type=int, default=3, help='input channel for generator')\n",
        "  parser.add_argument('--out_ngc', type=int, default=3, help='output channel for generator')\n",
        "  parser.add_argument('--in_ndc', type=int, default=3, help='input channel for discriminator')\n",
        "  parser.add_argument('--out_ndc', type=int, default=1, help='output channel for discriminator')\n",
        "  parser.add_argument('--batch_size', type=int, default=8, help='batch size')\n",
        "  parser.add_argument('--ngf', type=int, default=64)\n",
        "  parser.add_argument('--ndf', type=int, default=32)\n",
        "  parser.add_argument('--nb', type=int, default=8, help='the number of resnet block layer for generator')\n",
        "  parser.add_argument('--input_size', type=int, default=256, help='input size')\n",
        "  parser.add_argument('--train_epoch', type=int, default=100)\n",
        "  parser.add_argument('--pre_train_epoch', type=int, default=10)\n",
        "  parser.add_argument('--lrD', type=float, default=0.0002, help='learning rate, default=0.0002')\n",
        "  parser.add_argument('--lrG', type=float, default=0.0002, help='learning rate, default=0.0002')\n",
        "  parser.add_argument('--con_lambda', type=float, default=10, help='lambda for content loss')\n",
        "  parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for Adam optimizer')\n",
        "  parser.add_argument('--beta2', type=float, default=0.999, help='beta2 for Adam optimizer')\n",
        "  parser.add_argument('--latest_generator_model', required=False, default='', help='the latest trained model path')\n",
        "  parser.add_argument('--latest_discriminator_model', required=False, default='', help='the latest trained model path')\n",
        "  args = parser.parse_args(argv)\n",
        "\n",
        "  print('------------ Options -------------')\n",
        "  for k, v in sorted(vars(args).items()):\n",
        "      print('%s: %s' % (str(k), str(v)))\n",
        "  print('-------------- End ----------------')\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  if torch.backends.cudnn.enabled:\n",
        "      torch.backends.cudnn.benchmark = True\n",
        "\n",
        "  # results save path\n",
        "  if not os.path.isdir(os.path.join(args.name + '_results', 'Reconstruction')):\n",
        "      os.makedirs(os.path.join(args.name + '_results', 'Reconstruction'))\n",
        "  if not os.path.isdir(os.path.join(args.name + '_results', 'Transfer')):\n",
        "      os.makedirs(os.path.join(args.name + '_results', 'Transfer'))\n",
        "\n",
        "  # edge-promoting\n",
        "  if not os.path.isdir(os.path.join('data', args.tgt_data, 'pair')):\n",
        "      print('edge-promoting start!!')\n",
        "      edge_promoting(os.path.join('data', args.tgt_data, 'train'), os.path.join('data', args.tgt_data, 'pair'))\n",
        "  else:\n",
        "      print('edge-promoting already done')\n",
        "\n",
        "  # data_loader\n",
        "  src_transform = transforms.Compose([\n",
        "          transforms.Resize((args.input_size, args.input_size)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "  ])\n",
        "  tgt_transform = transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "  ])\n",
        "  train_loader_src = data_load(os.path.join('data', args.src_data), 'train', src_transform, args.batch_size, shuffle=True, drop_last=True)\n",
        "  train_loader_tgt = data_load(os.path.join('data', args.tgt_data), 'pair', tgt_transform, args.batch_size, shuffle=True, drop_last=True)\n",
        "  test_loader_src = data_load(os.path.join('data', args.src_data), 'test', src_transform, 1, shuffle=True, drop_last=True)\n",
        "\n",
        "  # network\n",
        "  G = generator(args.in_ngc, args.out_ngc, args.ngf, args.nb)\n",
        "  if args.latest_generator_model != '':\n",
        "      if torch.cuda.is_available():\n",
        "          G.load_state_dict(torch.load(args.latest_generator_model))\n",
        "      else:\n",
        "          # cpu mode\n",
        "          G.load_state_dict(torch.load(args.latest_generator_model, map_location=lambda storage, loc: storage))\n",
        "\n",
        "  D = discriminator(args.in_ndc, args.out_ndc, args.ndf)\n",
        "  if args.latest_discriminator_model != '':\n",
        "      if torch.cuda.is_available():\n",
        "          D.load_state_dict(torch.load(args.latest_discriminator_model))\n",
        "      else:\n",
        "          D.load_state_dict(torch.load(args.latest_discriminator_model, map_location=lambda storage, loc: storage))\n",
        "  VGG = VGG19(init_weights=args.vgg_model, feature_mode=True)\n",
        "  G.to(device)\n",
        "  D.to(device)\n",
        "  VGG.to(device)\n",
        "  G.train()\n",
        "  D.train()\n",
        "  VGG.eval()\n",
        "  print('---------- Networks initialized -------------')\n",
        "  print_network(G)\n",
        "  print_network(D)\n",
        "  print_network(VGG)\n",
        "  print('-----------------------------------------------')\n",
        "\n",
        "  # loss\n",
        "  BCE_loss = nn.BCELoss().to(device)\n",
        "  L1_loss = nn.L1Loss().to(device)\n",
        "\n",
        "  # Adam optimizer\n",
        "  G_optimizer = optim.Adam(G.parameters(), lr=args.lrG, betas=(args.beta1, args.beta2))\n",
        "  D_optimizer = optim.Adam(D.parameters(), lr=args.lrD, betas=(args.beta1, args.beta2))\n",
        "  G_scheduler = optim.lr_scheduler.MultiStepLR(optimizer=G_optimizer, milestones=[args.train_epoch // 2, args.train_epoch // 4 * 3], gamma=0.1)\n",
        "  D_scheduler = optim.lr_scheduler.MultiStepLR(optimizer=D_optimizer, milestones=[args.train_epoch // 2, args.train_epoch // 4 * 3], gamma=0.1)\n",
        "\n",
        "  pre_train_hist = {}\n",
        "  pre_train_hist['Recon_loss'] = []\n",
        "  pre_train_hist['per_epoch_time'] = []\n",
        "  pre_train_hist['total_time'] = []\n",
        "\n",
        "  \"\"\" Pre-train reconstruction \"\"\"\n",
        "  if args.latest_generator_model == '':\n",
        "      print('Pre-training start!')\n",
        "      start_time = time.time()\n",
        "      for epoch in range(args.pre_train_epoch):\n",
        "          epoch_start_time = time.time()\n",
        "          Recon_losses = []\n",
        "          for x, _ in train_loader_src:\n",
        "              x = x.to(device)\n",
        "\n",
        "              # train generator G\n",
        "              G_optimizer.zero_grad()\n",
        "\n",
        "              x_feature = VGG((x + 1) / 2)\n",
        "              G_ = G(x)\n",
        "              G_feature = VGG((G_ + 1) / 2)\n",
        "\n",
        "              Recon_loss = 10 * L1_loss(G_feature, x_feature.detach())\n",
        "              Recon_losses.append(Recon_loss.item())\n",
        "              pre_train_hist['Recon_loss'].append(Recon_loss.item())\n",
        "\n",
        "              Recon_loss.backward()\n",
        "              G_optimizer.step()\n",
        "\n",
        "          per_epoch_time = time.time() - epoch_start_time\n",
        "          pre_train_hist['per_epoch_time'].append(per_epoch_time)\n",
        "          print('[%d/%d] - time: %.2f, Recon loss: %.3f' % ((epoch + 1), args.pre_train_epoch, per_epoch_time, torch.mean(torch.FloatTensor(Recon_losses))))\n",
        "\n",
        "      total_time = time.time() - start_time\n",
        "      pre_train_hist['total_time'].append(total_time)\n",
        "      with open(os.path.join(args.name + '_results',  'pre_train_hist.pkl'), 'wb') as f:\n",
        "          pickle.dump(pre_train_hist, f)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          G.eval()\n",
        "          for n, (x, _) in enumerate(train_loader_src):\n",
        "              x = x.to(device)\n",
        "              G_recon = G(x)\n",
        "              result = torch.cat((x[0], G_recon[0]), 2)\n",
        "              path = os.path.join(args.name + '_results', 'Reconstruction', args.name + '_train_recon_' + str(n + 1) + '.png')\n",
        "              plt.imsave(path, (result.cpu().numpy().transpose(1, 2, 0) + 1) / 2)\n",
        "              if n == 4:\n",
        "                  break\n",
        "\n",
        "          for n, (x, _) in enumerate(test_loader_src):\n",
        "              x = x.to(device)\n",
        "              G_recon = G(x)\n",
        "              result = torch.cat((x[0], G_recon[0]), 2)\n",
        "              path = os.path.join(args.name + '_results', 'Reconstruction', args.name + '_test_recon_' + str(n + 1) + '.png')\n",
        "              plt.imsave(path, (result.cpu().numpy().transpose(1, 2, 0) + 1) / 2)\n",
        "              if n == 4:\n",
        "                  break\n",
        "  else:\n",
        "      print('Load the latest generator model, no need to pre-train')\n",
        "\n",
        "\n",
        "  train_hist = {}\n",
        "  train_hist['Disc_loss'] = []\n",
        "  train_hist['Gen_loss'] = []\n",
        "  train_hist['Con_loss'] = []\n",
        "  train_hist['per_epoch_time'] = []\n",
        "  train_hist['total_time'] = []\n",
        "  print('training start!')\n",
        "  start_time = time.time()\n",
        "  real = torch.ones(args.batch_size, 1, args.input_size // 4, args.input_size // 4).to(device)\n",
        "  fake = torch.zeros(args.batch_size, 1, args.input_size // 4, args.input_size // 4).to(device)\n",
        "  for epoch in range(args.train_epoch):\n",
        "      epoch_start_time = time.time()\n",
        "      G.train()\n",
        "      G_scheduler.step()\n",
        "      D_scheduler.step()\n",
        "      Disc_losses = []\n",
        "      Gen_losses = []\n",
        "      Con_losses = []\n",
        "      for (x, _), (y, _) in zip(train_loader_src, train_loader_tgt):\n",
        "          e = y[:, :, :, args.input_size:]\n",
        "          y = y[:, :, :, :args.input_size]\n",
        "          x, y, e = x.to(device), y.to(device), e.to(device)\n",
        "\n",
        "          # train D\n",
        "          D_optimizer.zero_grad()\n",
        "\n",
        "          D_real = D(y)\n",
        "          D_real_loss = BCE_loss(D_real, real)\n",
        "\n",
        "          G_ = G(x)\n",
        "          D_fake = D(G_)\n",
        "          D_fake_loss = BCE_loss(D_fake, fake)\n",
        "\n",
        "          D_edge = D(e)\n",
        "          D_edge_loss = BCE_loss(D_edge, fake)\n",
        "\n",
        "          Disc_loss = D_real_loss + D_fake_loss + D_edge_loss\n",
        "          Disc_losses.append(Disc_loss.item())\n",
        "          train_hist['Disc_loss'].append(Disc_loss.item())\n",
        "\n",
        "          Disc_loss.backward()\n",
        "          D_optimizer.step()\n",
        "\n",
        "          # train G\n",
        "          G_optimizer.zero_grad()\n",
        "\n",
        "          G_ = G(x)\n",
        "          D_fake = D(G_)\n",
        "          D_fake_loss = BCE_loss(D_fake, real)\n",
        "\n",
        "          x_feature = VGG((x + 1) / 2)\n",
        "          G_feature = VGG((G_ + 1) / 2)\n",
        "          Con_loss = args.con_lambda * L1_loss(G_feature, x_feature.detach())\n",
        "\n",
        "          Gen_loss = D_fake_loss + Con_loss\n",
        "          Gen_losses.append(D_fake_loss.item())\n",
        "          train_hist['Gen_loss'].append(D_fake_loss.item())\n",
        "          Con_losses.append(Con_loss.item())\n",
        "          train_hist['Con_loss'].append(Con_loss.item())\n",
        "\n",
        "          Gen_loss.backward()\n",
        "          G_optimizer.step()\n",
        "\n",
        "\n",
        "      per_epoch_time = time.time() - epoch_start_time\n",
        "      train_hist['per_epoch_time'].append(per_epoch_time)\n",
        "      print(\n",
        "      '[%d/%d] - time: %.2f, Disc loss: %.3f, Gen loss: %.3f, Con loss: %.3f' % ((epoch + 1), args.train_epoch, per_epoch_time, torch.mean(torch.FloatTensor(Disc_losses)),\n",
        "          torch.mean(torch.FloatTensor(Gen_losses)), torch.mean(torch.FloatTensor(Con_losses))))\n",
        "\n",
        "      if epoch % 2 == 1 or epoch == args.train_epoch - 1:\n",
        "          with torch.no_grad():\n",
        "              G.eval()\n",
        "              for n, (x, _) in enumerate(train_loader_src):\n",
        "                  x = x.to(device)\n",
        "                  G_recon = G(x)\n",
        "                  result = torch.cat((x[0], G_recon[0]), 2)\n",
        "                  path = os.path.join(args.name + '_results', 'Transfer', str(epoch+1) + '_epoch_' + args.name + '_train_' + str(n + 1) + '.png')\n",
        "                  plt.imsave(path, (result.cpu().numpy().transpose(1, 2, 0) + 1) / 2)\n",
        "                  if n == 4:\n",
        "                      break\n",
        "\n",
        "              for n, (x, _) in enumerate(test_loader_src):\n",
        "                  x = x.to(device)\n",
        "                  G_recon = G(x)\n",
        "                  result = torch.cat((x[0], G_recon[0]), 2)\n",
        "                  path = os.path.join(args.name + '_results', 'Transfer', str(epoch+1) + '_epoch_' + args.name + '_test_' + str(n + 1) + '.png')\n",
        "                  plt.imsave(path, (result.cpu().numpy().transpose(1, 2, 0) + 1) / 2)\n",
        "                  if n == 4:\n",
        "                      break\n",
        "\n",
        "              torch.save(G.state_dict(), os.path.join(args.name + '_results', 'generator_latest.pkl'))\n",
        "              torch.save(D.state_dict(), os.path.join(args.name + '_results', 'discriminator_latest.pkl'))\n",
        "\n",
        "  total_time = time.time() - start_time\n",
        "  train_hist['total_time'].append(total_time)\n",
        "\n",
        "  print(\"Avg one epoch time: %.2f, total %d epochs time: %.2f\" % (torch.mean(torch.FloatTensor(train_hist['per_epoch_time'])), args.train_epoch, total_time))\n",
        "  print(\"Training finish!... save training results\")\n",
        "\n",
        "  torch.save(G.state_dict(), os.path.join(args.name + '_results',  'generator_param.pkl'))\n",
        "  torch.save(D.state_dict(), os.path.join(args.name + '_results',  'discriminator_param.pkl'))\n",
        "  with open(os.path.join(args.name + '_results',  'train_hist.pkl'), 'wb') as f:\n",
        "      pickle.dump(train_hist, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTCxE6B5XOUJ",
        "outputId": "98caac41-e167-4a54-8d50-456ba3babdef"
      },
      "source": [
        "%cd /content/drive/MyDrive/CMU/SP21/18786-IDL/11785-final-project/exp_res\n",
        "main([\n",
        "    \"--name\", \"bridge-flame\",\n",
        "    \"--src_data\", \"/content/11785-project/data/src_cartoonflame\", \n",
        "    \"--tgt_data\", \"/content/11785-project/data/tgt_shinkai\",\n",
        "    \"--vgg_model\",\"/content/drive/MyDrive/CMU/SP21/18786-IDL/11785-final-project/vgg19-dcbb9e9d.pth\",\n",
        "    \"--train_epoch\", \"200\"])\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CMU/SP21/18786-IDL/11785-final-project/exp_res\n",
            "------------ Options -------------\n",
            "batch_size: 8\n",
            "beta1: 0.5\n",
            "beta2: 0.999\n",
            "con_lambda: 10\n",
            "in_ndc: 3\n",
            "in_ngc: 3\n",
            "input_size: 256\n",
            "latest_discriminator_model: \n",
            "latest_generator_model: \n",
            "lrD: 0.0002\n",
            "lrG: 0.0002\n",
            "name: bridge-flame\n",
            "nb: 8\n",
            "ndf: 32\n",
            "ngf: 64\n",
            "out_ndc: 1\n",
            "out_ngc: 3\n",
            "pre_train_epoch: 10\n",
            "src_data: /content/11785-project/data/src_cartoonflame\n",
            "tgt_data: /content/11785-project/data/tgt_shinkai\n",
            "train_epoch: 200\n",
            "vgg_model: /content/drive/MyDrive/CMU/SP21/18786-IDL/11785-final-project/vgg19-dcbb9e9d.pth\n",
            "-------------- End ----------------\n",
            "edge-promoting already done\n",
            "---------- Networks initialized -------------\n",
            "generator(\n",
            "  (down_convs): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (10): ReLU(inplace=True)\n",
            "  )\n",
            "  (resnet_blocks): Sequential(\n",
            "    (0): resnet_block(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    )\n",
            "    (1): resnet_block(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    )\n",
            "    (2): resnet_block(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    )\n",
            "    (3): resnet_block(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    )\n",
            "    (4): resnet_block(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    )\n",
            "    (5): resnet_block(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    )\n",
            "    (6): resnet_block(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    )\n",
            "    (7): resnet_block(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    )\n",
            "  )\n",
            "  (up_convs): Sequential(\n",
            "    (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "    (9): Tanh()\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 11120195\n",
            "discriminator(\n",
            "  (convs): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (14): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (15): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): Sigmoid()\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 1128385\n",
            "VGG19(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): ReLU(inplace=True)\n",
            "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): ReLU(inplace=True)\n",
            "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 143667240\n",
            "-----------------------------------------------\n",
            "Pre-training start!\n",
            "[1/10] - time: 52.40, Recon loss: 18.077\n",
            "[2/10] - time: 50.89, Recon loss: 11.407\n",
            "[3/10] - time: 50.91, Recon loss: 9.551\n",
            "[4/10] - time: 50.90, Recon loss: 8.674\n",
            "[5/10] - time: 50.92, Recon loss: 7.983\n",
            "[6/10] - time: 50.92, Recon loss: 7.526\n",
            "[7/10] - time: 50.92, Recon loss: 7.122\n",
            "[8/10] - time: 50.91, Recon loss: 6.848\n",
            "[9/10] - time: 50.92, Recon loss: 6.245\n",
            "[10/10] - time: 50.92, Recon loss: 5.789\n",
            "training start!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1/200] - time: 104.79, Disc loss: 1.634, Gen loss: 2.046, Con loss: 5.327\n",
            "[2/200] - time: 104.84, Disc loss: 1.626, Gen loss: 2.577, Con loss: 5.268\n",
            "[3/200] - time: 104.67, Disc loss: 1.598, Gen loss: 2.291, Con loss: 5.345\n",
            "[4/200] - time: 104.85, Disc loss: 1.384, Gen loss: 2.320, Con loss: 5.200\n",
            "[5/200] - time: 104.64, Disc loss: 1.001, Gen loss: 2.492, Con loss: 5.273\n",
            "[6/200] - time: 104.84, Disc loss: 0.849, Gen loss: 2.806, Con loss: 5.771\n",
            "[7/200] - time: 104.65, Disc loss: 0.842, Gen loss: 2.758, Con loss: 6.251\n",
            "[8/200] - time: 104.85, Disc loss: 0.730, Gen loss: 2.933, Con loss: 6.071\n",
            "[9/200] - time: 104.66, Disc loss: 0.748, Gen loss: 3.007, Con loss: 6.080\n",
            "[10/200] - time: 104.85, Disc loss: 0.572, Gen loss: 3.301, Con loss: 6.426\n",
            "[11/200] - time: 104.65, Disc loss: 0.638, Gen loss: 3.210, Con loss: 6.464\n",
            "[12/200] - time: 104.84, Disc loss: 0.542, Gen loss: 3.416, Con loss: 6.221\n",
            "[13/200] - time: 104.66, Disc loss: 0.524, Gen loss: 3.643, Con loss: 6.078\n",
            "[14/200] - time: 104.85, Disc loss: 0.528, Gen loss: 3.448, Con loss: 6.583\n",
            "[15/200] - time: 104.64, Disc loss: 0.407, Gen loss: 3.795, Con loss: 6.052\n",
            "[16/200] - time: 104.85, Disc loss: 0.491, Gen loss: 3.693, Con loss: 5.999\n",
            "[17/200] - time: 104.64, Disc loss: 0.368, Gen loss: 4.020, Con loss: 6.293\n",
            "[18/200] - time: 104.81, Disc loss: 0.299, Gen loss: 4.451, Con loss: 5.586\n",
            "[19/200] - time: 104.63, Disc loss: 0.463, Gen loss: 3.918, Con loss: 5.959\n",
            "[20/200] - time: 104.85, Disc loss: 0.329, Gen loss: 4.137, Con loss: 5.838\n",
            "[21/200] - time: 104.63, Disc loss: 0.811, Gen loss: 3.464, Con loss: 5.635\n",
            "[22/200] - time: 104.85, Disc loss: 0.386, Gen loss: 3.807, Con loss: 5.647\n",
            "[23/200] - time: 104.66, Disc loss: 0.359, Gen loss: 4.144, Con loss: 5.561\n",
            "[24/200] - time: 104.84, Disc loss: 0.351, Gen loss: 4.271, Con loss: 5.649\n",
            "[25/200] - time: 104.65, Disc loss: 0.324, Gen loss: 4.475, Con loss: 5.389\n",
            "[26/200] - time: 104.83, Disc loss: 0.219, Gen loss: 4.812, Con loss: 5.189\n",
            "[27/200] - time: 104.63, Disc loss: 0.290, Gen loss: 4.691, Con loss: 5.233\n",
            "[28/200] - time: 104.82, Disc loss: 0.134, Gen loss: 5.301, Con loss: 4.625\n",
            "[29/200] - time: 104.65, Disc loss: 0.193, Gen loss: 5.490, Con loss: 4.611\n",
            "[30/200] - time: 104.83, Disc loss: 0.339, Gen loss: 4.681, Con loss: 5.393\n",
            "[31/200] - time: 104.65, Disc loss: 0.342, Gen loss: 4.775, Con loss: 5.341\n",
            "[32/200] - time: 104.82, Disc loss: 0.257, Gen loss: 4.883, Con loss: 5.251\n",
            "[33/200] - time: 104.61, Disc loss: 0.310, Gen loss: 4.732, Con loss: 5.430\n",
            "[34/200] - time: 104.82, Disc loss: 0.307, Gen loss: 4.911, Con loss: 5.527\n",
            "[35/200] - time: 104.60, Disc loss: 0.242, Gen loss: 4.995, Con loss: 5.083\n",
            "[36/200] - time: 104.82, Disc loss: 0.275, Gen loss: 5.119, Con loss: 5.038\n",
            "[37/200] - time: 104.62, Disc loss: 0.318, Gen loss: 4.837, Con loss: 4.924\n",
            "[38/200] - time: 104.80, Disc loss: 0.276, Gen loss: 5.054, Con loss: 5.047\n",
            "[39/200] - time: 104.60, Disc loss: 0.306, Gen loss: 4.822, Con loss: 5.096\n",
            "[40/200] - time: 104.81, Disc loss: 0.546, Gen loss: 4.342, Con loss: 5.651\n",
            "[41/200] - time: 104.63, Disc loss: 0.457, Gen loss: 3.615, Con loss: 5.747\n",
            "[42/200] - time: 104.79, Disc loss: 0.428, Gen loss: 3.814, Con loss: 5.819\n",
            "[43/200] - time: 104.60, Disc loss: 0.461, Gen loss: 3.849, Con loss: 5.927\n",
            "[44/200] - time: 104.81, Disc loss: 0.471, Gen loss: 3.664, Con loss: 5.939\n",
            "[45/200] - time: 104.61, Disc loss: 0.463, Gen loss: 3.829, Con loss: 5.768\n",
            "[46/200] - time: 104.81, Disc loss: 0.432, Gen loss: 3.985, Con loss: 5.811\n",
            "[47/200] - time: 104.60, Disc loss: 0.388, Gen loss: 3.971, Con loss: 6.096\n",
            "[48/200] - time: 104.80, Disc loss: 0.372, Gen loss: 4.248, Con loss: 5.942\n",
            "[49/200] - time: 104.58, Disc loss: 0.438, Gen loss: 4.006, Con loss: 5.916\n",
            "[50/200] - time: 104.81, Disc loss: 0.411, Gen loss: 4.018, Con loss: 5.745\n",
            "[51/200] - time: 104.59, Disc loss: 0.432, Gen loss: 3.971, Con loss: 5.881\n",
            "[52/200] - time: 104.77, Disc loss: 0.463, Gen loss: 4.001, Con loss: 5.856\n",
            "[53/200] - time: 104.58, Disc loss: 0.430, Gen loss: 3.883, Con loss: 6.006\n",
            "[54/200] - time: 104.81, Disc loss: 0.440, Gen loss: 4.063, Con loss: 5.716\n",
            "[55/200] - time: 104.60, Disc loss: 0.400, Gen loss: 3.961, Con loss: 5.891\n",
            "[56/200] - time: 104.81, Disc loss: 0.420, Gen loss: 3.928, Con loss: 5.913\n",
            "[57/200] - time: 104.65, Disc loss: 0.418, Gen loss: 4.007, Con loss: 6.049\n",
            "[58/200] - time: 104.81, Disc loss: 0.419, Gen loss: 4.097, Con loss: 6.044\n",
            "[59/200] - time: 104.60, Disc loss: 0.354, Gen loss: 4.184, Con loss: 6.440\n",
            "[60/200] - time: 104.82, Disc loss: 0.390, Gen loss: 4.196, Con loss: 6.294\n",
            "[61/200] - time: 104.61, Disc loss: 0.402, Gen loss: 4.235, Con loss: 5.968\n",
            "[62/200] - time: 104.81, Disc loss: 0.321, Gen loss: 4.547, Con loss: 5.881\n",
            "[63/200] - time: 104.62, Disc loss: 0.318, Gen loss: 4.601, Con loss: 5.685\n",
            "[64/200] - time: 104.79, Disc loss: 0.379, Gen loss: 4.414, Con loss: 5.816\n",
            "[65/200] - time: 104.59, Disc loss: 0.371, Gen loss: 4.281, Con loss: 5.620\n",
            "[66/200] - time: 104.83, Disc loss: 0.379, Gen loss: 4.396, Con loss: 5.385\n",
            "[67/200] - time: 104.60, Disc loss: 0.346, Gen loss: 4.406, Con loss: 5.653\n",
            "[68/200] - time: 104.78, Disc loss: 0.329, Gen loss: 4.502, Con loss: 5.611\n",
            "[69/200] - time: 104.63, Disc loss: 1.399, Gen loss: 4.151, Con loss: 5.239\n",
            "[70/200] - time: 104.78, Disc loss: 0.473, Gen loss: 3.300, Con loss: 4.916\n",
            "[71/200] - time: 104.60, Disc loss: 0.361, Gen loss: 4.064, Con loss: 5.030\n",
            "[72/200] - time: 104.80, Disc loss: 0.370, Gen loss: 4.284, Con loss: 5.118\n",
            "[73/200] - time: 104.59, Disc loss: 0.389, Gen loss: 4.228, Con loss: 5.468\n",
            "[74/200] - time: 104.80, Disc loss: 0.368, Gen loss: 4.558, Con loss: 5.718\n",
            "[75/200] - time: 104.63, Disc loss: 0.313, Gen loss: 4.683, Con loss: 5.425\n",
            "[76/200] - time: 104.79, Disc loss: 0.333, Gen loss: 4.492, Con loss: 5.239\n",
            "[77/200] - time: 104.62, Disc loss: 0.351, Gen loss: 4.586, Con loss: 5.248\n",
            "[78/200] - time: 104.78, Disc loss: 0.325, Gen loss: 4.576, Con loss: 5.386\n",
            "[79/200] - time: 104.58, Disc loss: 0.319, Gen loss: 4.667, Con loss: 5.230\n",
            "[80/200] - time: 104.78, Disc loss: 0.323, Gen loss: 4.740, Con loss: 5.729\n",
            "[81/200] - time: 104.60, Disc loss: 0.358, Gen loss: 4.573, Con loss: 5.369\n",
            "[82/200] - time: 104.77, Disc loss: 0.351, Gen loss: 4.604, Con loss: 5.283\n",
            "[83/200] - time: 104.58, Disc loss: 0.339, Gen loss: 4.694, Con loss: 5.162\n",
            "[84/200] - time: 104.81, Disc loss: 0.352, Gen loss: 4.642, Con loss: 5.201\n",
            "[85/200] - time: 104.59, Disc loss: 0.364, Gen loss: 4.585, Con loss: 5.268\n",
            "[86/200] - time: 104.76, Disc loss: 0.348, Gen loss: 4.665, Con loss: 5.241\n",
            "[87/200] - time: 104.59, Disc loss: 0.373, Gen loss: 4.681, Con loss: 5.341\n",
            "[88/200] - time: 104.79, Disc loss: 0.361, Gen loss: 4.696, Con loss: 5.214\n",
            "[89/200] - time: 104.57, Disc loss: 0.315, Gen loss: 4.817, Con loss: 5.200\n",
            "[90/200] - time: 104.76, Disc loss: 0.332, Gen loss: 4.806, Con loss: 5.236\n",
            "[91/200] - time: 104.57, Disc loss: 0.277, Gen loss: 4.927, Con loss: 5.284\n",
            "[92/200] - time: 104.79, Disc loss: 0.406, Gen loss: 4.620, Con loss: 5.263\n",
            "[93/200] - time: 104.57, Disc loss: 0.346, Gen loss: 4.683, Con loss: 5.225\n",
            "[94/200] - time: 104.77, Disc loss: 0.334, Gen loss: 4.758, Con loss: 5.321\n",
            "[95/200] - time: 104.55, Disc loss: 0.321, Gen loss: 4.863, Con loss: 5.197\n",
            "[96/200] - time: 104.79, Disc loss: 0.351, Gen loss: 4.869, Con loss: 5.164\n",
            "[97/200] - time: 104.59, Disc loss: 0.381, Gen loss: 4.757, Con loss: 5.167\n",
            "[98/200] - time: 104.77, Disc loss: 0.379, Gen loss: 4.748, Con loss: 5.131\n",
            "[99/200] - time: 104.60, Disc loss: 0.339, Gen loss: 4.836, Con loss: 5.279\n",
            "[100/200] - time: 104.75, Disc loss: 0.252, Gen loss: 4.616, Con loss: 4.958\n",
            "[101/200] - time: 104.56, Disc loss: 0.253, Gen loss: 4.760, Con loss: 4.842\n",
            "[102/200] - time: 104.77, Disc loss: 0.242, Gen loss: 4.811, Con loss: 4.868\n",
            "[103/200] - time: 104.56, Disc loss: 0.230, Gen loss: 4.856, Con loss: 4.841\n",
            "[104/200] - time: 104.79, Disc loss: 0.259, Gen loss: 4.689, Con loss: 4.841\n",
            "[105/200] - time: 104.56, Disc loss: 0.256, Gen loss: 4.692, Con loss: 4.838\n",
            "[106/200] - time: 104.77, Disc loss: 0.260, Gen loss: 4.683, Con loss: 4.829\n",
            "[107/200] - time: 104.59, Disc loss: 0.255, Gen loss: 4.611, Con loss: 4.862\n",
            "[108/200] - time: 104.74, Disc loss: 0.251, Gen loss: 4.691, Con loss: 4.850\n",
            "[109/200] - time: 104.56, Disc loss: 0.259, Gen loss: 4.651, Con loss: 4.837\n",
            "[110/200] - time: 104.75, Disc loss: 0.250, Gen loss: 4.716, Con loss: 4.870\n",
            "[111/200] - time: 104.56, Disc loss: 0.267, Gen loss: 4.601, Con loss: 4.844\n",
            "[112/200] - time: 104.77, Disc loss: 0.274, Gen loss: 4.674, Con loss: 4.830\n",
            "[113/200] - time: 104.58, Disc loss: 0.301, Gen loss: 4.520, Con loss: 4.840\n",
            "[114/200] - time: 104.76, Disc loss: 0.280, Gen loss: 4.614, Con loss: 4.775\n",
            "[115/200] - time: 104.57, Disc loss: 0.286, Gen loss: 4.575, Con loss: 4.736\n",
            "[116/200] - time: 104.78, Disc loss: 0.259, Gen loss: 4.584, Con loss: 4.745\n",
            "[117/200] - time: 104.57, Disc loss: 0.286, Gen loss: 4.579, Con loss: 4.770\n",
            "[118/200] - time: 104.78, Disc loss: 0.293, Gen loss: 4.537, Con loss: 4.768\n",
            "[119/200] - time: 104.57, Disc loss: 0.264, Gen loss: 4.634, Con loss: 4.701\n",
            "[120/200] - time: 104.78, Disc loss: 0.260, Gen loss: 4.672, Con loss: 4.706\n",
            "[121/200] - time: 104.58, Disc loss: 0.273, Gen loss: 4.587, Con loss: 4.714\n",
            "[122/200] - time: 104.75, Disc loss: 0.293, Gen loss: 4.543, Con loss: 4.709\n",
            "[123/200] - time: 104.56, Disc loss: 0.267, Gen loss: 4.625, Con loss: 4.628\n",
            "[124/200] - time: 104.76, Disc loss: 0.276, Gen loss: 4.623, Con loss: 4.648\n",
            "[125/200] - time: 104.58, Disc loss: 0.283, Gen loss: 4.565, Con loss: 4.705\n",
            "[126/200] - time: 104.75, Disc loss: 0.250, Gen loss: 4.700, Con loss: 4.707\n",
            "[127/200] - time: 104.61, Disc loss: 0.272, Gen loss: 4.727, Con loss: 4.708\n",
            "[128/200] - time: 104.76, Disc loss: 0.288, Gen loss: 4.575, Con loss: 4.666\n",
            "[129/200] - time: 104.57, Disc loss: 0.289, Gen loss: 4.623, Con loss: 4.655\n",
            "[130/200] - time: 104.75, Disc loss: 0.274, Gen loss: 4.620, Con loss: 4.650\n",
            "[131/200] - time: 104.57, Disc loss: 0.272, Gen loss: 4.738, Con loss: 4.640\n",
            "[132/200] - time: 104.75, Disc loss: 0.291, Gen loss: 4.632, Con loss: 4.723\n",
            "[133/200] - time: 104.58, Disc loss: 0.277, Gen loss: 4.584, Con loss: 4.681\n",
            "[134/200] - time: 104.78, Disc loss: 0.262, Gen loss: 4.723, Con loss: 4.630\n",
            "[135/200] - time: 104.58, Disc loss: 0.275, Gen loss: 4.693, Con loss: 4.628\n",
            "[136/200] - time: 104.78, Disc loss: 0.288, Gen loss: 4.795, Con loss: 4.647\n",
            "[137/200] - time: 104.56, Disc loss: 0.305, Gen loss: 4.627, Con loss: 4.609\n",
            "[138/200] - time: 104.78, Disc loss: 0.280, Gen loss: 4.657, Con loss: 4.637\n",
            "[139/200] - time: 104.58, Disc loss: 0.291, Gen loss: 4.614, Con loss: 4.587\n",
            "[140/200] - time: 104.75, Disc loss: 0.269, Gen loss: 4.625, Con loss: 4.582\n",
            "[141/200] - time: 104.56, Disc loss: 0.287, Gen loss: 4.631, Con loss: 4.611\n",
            "[142/200] - time: 104.75, Disc loss: 0.301, Gen loss: 4.670, Con loss: 4.594\n",
            "[143/200] - time: 104.56, Disc loss: 0.272, Gen loss: 4.633, Con loss: 4.582\n",
            "[144/200] - time: 104.74, Disc loss: 0.293, Gen loss: 4.689, Con loss: 4.568\n",
            "[145/200] - time: 104.56, Disc loss: 0.297, Gen loss: 4.687, Con loss: 4.561\n",
            "[146/200] - time: 104.77, Disc loss: 0.293, Gen loss: 4.625, Con loss: 4.533\n",
            "[147/200] - time: 104.54, Disc loss: 0.296, Gen loss: 4.691, Con loss: 4.566\n",
            "[148/200] - time: 104.74, Disc loss: 0.296, Gen loss: 4.702, Con loss: 4.552\n",
            "[149/200] - time: 104.56, Disc loss: 0.267, Gen loss: 4.647, Con loss: 4.551\n",
            "[150/200] - time: 104.77, Disc loss: 0.275, Gen loss: 4.613, Con loss: 4.540\n",
            "[151/200] - time: 104.56, Disc loss: 0.266, Gen loss: 4.595, Con loss: 4.526\n",
            "[152/200] - time: 104.77, Disc loss: 0.277, Gen loss: 4.605, Con loss: 4.528\n",
            "[153/200] - time: 104.57, Disc loss: 0.278, Gen loss: 4.583, Con loss: 4.530\n",
            "[154/200] - time: 104.78, Disc loss: 0.269, Gen loss: 4.630, Con loss: 4.524\n",
            "[155/200] - time: 104.58, Disc loss: 0.279, Gen loss: 4.617, Con loss: 4.521\n",
            "[156/200] - time: 104.77, Disc loss: 0.258, Gen loss: 4.669, Con loss: 4.522\n",
            "[157/200] - time: 104.57, Disc loss: 0.264, Gen loss: 4.636, Con loss: 4.533\n",
            "[158/200] - time: 104.77, Disc loss: 0.271, Gen loss: 4.627, Con loss: 4.523\n",
            "[159/200] - time: 104.57, Disc loss: 0.270, Gen loss: 4.609, Con loss: 4.529\n",
            "[160/200] - time: 104.76, Disc loss: 0.284, Gen loss: 4.602, Con loss: 4.518\n",
            "[161/200] - time: 104.56, Disc loss: 0.278, Gen loss: 4.610, Con loss: 4.525\n",
            "[162/200] - time: 104.77, Disc loss: 0.285, Gen loss: 4.616, Con loss: 4.523\n",
            "[163/200] - time: 104.57, Disc loss: 0.262, Gen loss: 4.623, Con loss: 4.535\n",
            "[164/200] - time: 104.77, Disc loss: 0.283, Gen loss: 4.559, Con loss: 4.532\n",
            "[165/200] - time: 104.56, Disc loss: 0.280, Gen loss: 4.636, Con loss: 4.522\n",
            "[166/200] - time: 104.77, Disc loss: 0.283, Gen loss: 4.586, Con loss: 4.523\n",
            "[167/200] - time: 104.56, Disc loss: 0.273, Gen loss: 4.621, Con loss: 4.524\n",
            "[168/200] - time: 104.76, Disc loss: 0.286, Gen loss: 4.558, Con loss: 4.530\n",
            "[169/200] - time: 104.56, Disc loss: 0.288, Gen loss: 4.606, Con loss: 4.529\n",
            "[170/200] - time: 104.76, Disc loss: 0.291, Gen loss: 4.584, Con loss: 4.516\n",
            "[171/200] - time: 104.56, Disc loss: 0.284, Gen loss: 4.599, Con loss: 4.525\n",
            "[172/200] - time: 104.75, Disc loss: 0.254, Gen loss: 4.641, Con loss: 4.519\n",
            "[173/200] - time: 104.55, Disc loss: 0.273, Gen loss: 4.615, Con loss: 4.521\n",
            "[174/200] - time: 104.76, Disc loss: 0.269, Gen loss: 4.611, Con loss: 4.524\n",
            "[175/200] - time: 104.58, Disc loss: 0.286, Gen loss: 4.602, Con loss: 4.516\n",
            "[176/200] - time: 104.76, Disc loss: 0.283, Gen loss: 4.592, Con loss: 4.517\n",
            "[177/200] - time: 104.56, Disc loss: 0.283, Gen loss: 4.614, Con loss: 4.519\n",
            "[178/200] - time: 104.76, Disc loss: 0.281, Gen loss: 4.611, Con loss: 4.520\n",
            "[179/200] - time: 104.57, Disc loss: 0.275, Gen loss: 4.626, Con loss: 4.513\n",
            "[180/200] - time: 104.77, Disc loss: 0.282, Gen loss: 4.606, Con loss: 4.528\n",
            "[181/200] - time: 104.56, Disc loss: 0.292, Gen loss: 4.608, Con loss: 4.525\n",
            "[182/200] - time: 104.76, Disc loss: 0.279, Gen loss: 4.607, Con loss: 4.517\n",
            "[183/200] - time: 104.55, Disc loss: 0.272, Gen loss: 4.636, Con loss: 4.513\n",
            "[184/200] - time: 104.74, Disc loss: 0.279, Gen loss: 4.628, Con loss: 4.523\n",
            "[185/200] - time: 104.54, Disc loss: 0.289, Gen loss: 4.640, Con loss: 4.533\n",
            "[186/200] - time: 104.75, Disc loss: 0.256, Gen loss: 4.640, Con loss: 4.521\n",
            "[187/200] - time: 104.56, Disc loss: 0.293, Gen loss: 4.622, Con loss: 4.526\n",
            "[188/200] - time: 104.76, Disc loss: 0.276, Gen loss: 4.596, Con loss: 4.509\n",
            "[189/200] - time: 104.58, Disc loss: 0.279, Gen loss: 4.534, Con loss: 4.519\n",
            "[190/200] - time: 104.75, Disc loss: 0.273, Gen loss: 4.594, Con loss: 4.514\n",
            "[191/200] - time: 104.59, Disc loss: 0.262, Gen loss: 4.581, Con loss: 4.521\n",
            "[192/200] - time: 104.94, Disc loss: 0.290, Gen loss: 4.585, Con loss: 4.524\n",
            "[193/200] - time: 104.75, Disc loss: 0.287, Gen loss: 4.609, Con loss: 4.519\n",
            "[194/200] - time: 104.95, Disc loss: 0.275, Gen loss: 4.603, Con loss: 4.522\n",
            "[195/200] - time: 104.77, Disc loss: 0.291, Gen loss: 4.617, Con loss: 4.523\n",
            "[196/200] - time: 104.96, Disc loss: 0.295, Gen loss: 4.605, Con loss: 4.517\n",
            "[197/200] - time: 104.78, Disc loss: 0.288, Gen loss: 4.568, Con loss: 4.522\n",
            "[198/200] - time: 104.96, Disc loss: 0.271, Gen loss: 4.645, Con loss: 4.523\n",
            "[199/200] - time: 104.78, Disc loss: 0.281, Gen loss: 4.602, Con loss: 4.517\n",
            "[200/200] - time: 104.98, Disc loss: 0.302, Gen loss: 4.559, Con loss: 4.516\n",
            "Avg one epoch time: 104.70, total 200 epochs time: 21360.58\n",
            "Training finish!... save training results\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}